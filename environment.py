TOKENIZER_DATA_PATH = './data/tokenizer_data.txt'
DATA_FILE_PATH = './data/dataset.npy'
SOURCE_DATA_FILE_PATH = './source_data/DaNetQA/train.jsonl'
WORD2IND_PATH = './data/word2ind.json'

MODEL_PATH = './model.pt'
BATCH_SIZE = 16
MAX_WINDOW_LEN = 11
EMBEDDINGS_SIZE = 200
EPOCHS = 1000
LR = 1e-2

PAD_WORD = '<pad>'